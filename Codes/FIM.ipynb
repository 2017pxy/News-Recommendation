{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('nn': conda)",
   "display_name": "Python 3.7.9 64-bit ('nn': conda)",
   "metadata": {
    "interpreter": {
     "hash": "9616ec0cf0e0dd041cba3c8886d471a5cc72bbf20e2c795f4079199200777fdd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import GloVe\n",
    "from utils.preprocess import MINDIterator\n",
    "from utils.utils import getVocab,getLoss,getLabel,constructBasicDict\n",
    "from utils.utils import run_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'mode':'small',\n",
    "    'batch_size':5,\n",
    "    'title_size':18,\n",
    "    'his_size':50,   \n",
    "    'npratio':4,     \n",
    "    'dropout_p':0.2,\n",
    "    'filter_num':150,\n",
    "    'embedding_dim':300,\n",
    "    'metrics':'group_auc,ndcg@4,mean_mrr',\n",
    "    'gpu':'cuda:0',\n",
    "    'load_mode':3\n",
    "}\n",
    "\n",
    "# customize your path here\n",
    "news_file = r'D:\\Data\\NR_data\\dev\\news.tsv'\n",
    "behavior_file_train = r'D:\\Data\\NR_data\\dev\\behaviors_train.tsv'\n",
    "behavior_file_test = r'D:\\Data\\NR_data\\dev\\behaviors_test.tsv'\n",
    "\n",
    "# if user2id,word2id,news2id hasn't been constructed\n",
    "if not os.path.exists('data/vocab_'+hparams['mode']+'.pkl'):\n",
    "    constructBasicDict(news_file,behavior_file_train,hparams['mode'])\n",
    "\n",
    "device = torch.device(hparams['gpu']) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "iterator = MINDIterator(hparams=hparams)\n",
    "\n",
    "# torchtext.Vocab.vocab object\n",
    "vocab = iterator.word_dict\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab.load_vectors(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FIMModel(nn.Module):\n",
    "    def __init__(self,hparam,vocab):\n",
    "        super().__init__()\n",
    "        self.npratio = hparams['npratio']\n",
    "        self.dropout_p = hparams['dropout_p']\n",
    "        self.metrics = hparams['metrics']\n",
    "\n",
    "        self.batch_size = hparams['batch_size']\n",
    "        self.title_size = hparams['title_size']\n",
    "        self.his_size =hparams['his_size']\n",
    "\n",
    "        self.filter_num = hparams['filter_num']\n",
    "        self.embedding_dim = hparams['embedding_dim']\n",
    "        self.user_dim = hparams['user_dim']\n",
    "        self.preference_dim =hparams['preference_dim']\n",
    "\n",
    "        self.device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "        # pretrained embedding\n",
    "        self.embedding = vocab.vectors\n",
    "        # elements in the slice along dim will sum up to 1 \n",
    "        self.softmax = nn.functional.softmax\n",
    "        \n",
    "        self.CNN_d1 = nn.Conv1d(in_channel=self.embedding_dim,out_channel=self.filter_num,kernel_size = self.kernel_size,dilation=1,padding=1)\n",
    "        self.CNN_d2 = nn.Conv1d(in_channel=self.filter_num,out_channel=self.filter_num,kernel_size = self.kernel_size,dilation=2,padding=2)\n",
    "        self.CNN_d1 = nn.Conv1d(in_channel=self.filter_num,out_channel=self.filter_num,kernel_size = self.kernel_size,dilation=3,padding=3)\n",
    "\n",
    "        self.RELU = nn.ReLU()\n",
    "        self.LayerNorm = nn.LayerNorm(self.filter_num,self.embedding_dim)\n",
    "\n",
    "    def _HDC(self,news_embedding_batch):\n",
    "        \"\"\" stack 1d CNN with dilation rate expanding from 1 to 3\n",
    "        \n",
    "        Returns:\n",
    "            dict: news_repr of in different lexical level(dilation rate)\n",
    "        \"\"\"\n",
    "        news_embedding_d1 = self.CNN_d1(news_embedding_batch)\n",
    "        news_embedding_d1 = self.LayerNorm(news_embedding_d1)\n",
    "        news_embedding_d1 = self.ReLU(news_embedding_d1)\n",
    "\n",
    "        news_embedding_d2 = self.CNN_d1(news_embedding_d1)\n",
    "        news_embedding_d2 = self.LayerNorm(news_embedding_d2)\n",
    "        news_embedding_d1 = self.ReLU(news_embedding_d2)        \n",
    "\n",
    "        news_embedding_d3 = self.CNN_d1(news_embedding_d2)\n",
    "        news_embedding_d3 = self.LayerNorm(news_embedding_d3)\n",
    "        news_embedding_d1 = self.ReLU(news_embedding_d3)\n",
    "        \n",
    "        return {\n",
    "            'd1':news_embedding_d1,\n",
    "            'd2':news_embedding_d2,\n",
    "            'd3':news_embedding_d3\n",
    "            }\n",
    "        \n",
    "    def _news_encoder(self,news_set):\n",
    "        \"\"\" encode set of news to news representation of [batch_size * filter_num * signal_length(title_size + category_length + subcategory_length)]\n",
    "        \n",
    "        Args:\n",
    "            news_set:\n",
    "        \n",
    "        Returns:\n",
    "            news_repr:\n",
    "        \"\"\"\n",
    "        news_embedding = self.embedding[news_set].permute(0,2,1).to(self.device)\n",
    "        news_embedding_stack = self._HDC(news_embedding)\n",
    "        return news_embedding_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = iterator.load_data_from_file(news_file,behavior_file_train)\n",
    "record = next(train)\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mind import MINDDataset\n",
    "from utils.utils import news_token_generator_group,constructBasicDict\n",
    "from torchtext.data.functional import simple_space_split,numericalize_tokens_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.data import Dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "hparams = {\n",
    "    'mode':'small',\n",
    "    'batch_size':5,\n",
    "    'title_size':18,\n",
    "    'his_size':50,   \n",
    "    'npratio':4,     \n",
    "    'dropout_p':0.2,\n",
    "    'filter_num':150,\n",
    "    'embedding_dim':300,\n",
    "    'metrics':'group_auc,ndcg@4,mean_mrr',\n",
    "    'gpu':'cuda:0',\n",
    "    'load_mode':3,\n",
    "    'col_spliter':'\\t'\n",
    "}\n",
    "news_file = r'D:\\Data\\NR_data\\dev\\news.tsv'\n",
    "behavior_file_train = r'D:\\Data\\NR_data\\dev\\behaviors_train.tsv'\n",
    "behavior_file_test = r'D:\\Data\\NR_data\\dev\\behaviors_test.tsv'\n",
    "\n",
    "if not os.path.exists('data/vocab_'+hparams['mode']+'.pkl'):\n",
    "    constructBasicDict(news_file,behavior_file_train,hparams['mode'],['title','category','subcategory'])\n",
    "\n",
    "mindDS = MINDDataset(hparams=hparams)\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = mindDS.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindDS._init_news(news_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,     0,     0,     0],\n",
       "       [    8,  3518,  1288, ...,     0,     0,     0],\n",
       "       [  370,   722,  3556, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  239,    12, 25014, ...,     0,     0,     0],\n",
       "       [   53,     8,  2699, ...,     0,     0,     0],\n",
       "       [   70,     4,   146, ...,     0,     0,     0]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "mindDS.news_title_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(51282, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "mindDS.subcategory_title_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}