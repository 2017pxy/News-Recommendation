{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bit4c03300bedca44f8b0013abe02048abc",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch\n",
    "\n",
    "### repeating samples along axis\n",
    "\n",
    "- *repeat_interleave* is equal to *cat and view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[1, 2]],\n\n        [[2, 3]]]) torch.Size([2, 1, 2])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1, 2]],\n",
       " \n",
       "         [[1, 2]],\n",
       " \n",
       "         [[2, 3]],\n",
       " \n",
       "         [[2, 3]]]),\n",
       " tensor([[[1, 2]],\n",
       " \n",
       "         [[1, 2]],\n",
       " \n",
       "         [[2, 3]],\n",
       " \n",
       "         [[2, 3]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a =torch.tensor([[[1,2]],[[2,3]]])\n",
    "print(a,a.shape)\n",
    "\n",
    "a.repeat_interleave(repeats=2,dim=0),torch.cat([a.unsqueeze(dim=1)]*2,dim=1).view(-1,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `permute`\n",
    "\n",
    "let's suppose there is a tensor of $[dim0, dim1, dim2, dim3]$, then we permute it to $[dim3, dim1, dim2, dim0]$\n",
    "\n",
    "- **consequence**: origin value at $[a, b, c, d]$ will be switched to $[d, b, c, a]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.zeros([5,4,3,2]),\n",
    "# say a=2, b=3, c=1, d=1,\n",
    "a[2,3,1,1] = 1,\n",
    "print(\"origin 1 at [2,3,1,1]: {}\".format(a[2,3,1,1])),\n",
    "b = a.permute(3,1,2,0),\n",
    "print(\"permuted 1 at [3,1,2,0]: {}\".format(b[1,3,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding non-zero indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.zeros(2,2)\n",
    "a[1,0] = 1\n",
    "a.nonzero()"
   ]
  },
  {
   "source": [
    "### tensor multiplication\n",
    "\n",
    "Docs about `matmul` function is concise, I want to give an example:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [1, 0, 0]],\n",
       " \n",
       "         [[2, 3, 4],\n",
       "          [0, 1, 0]]]),\n",
       " torch.Size([2, 2, 3]),\n",
       " tensor([[[1, 0],\n",
       "          [0, 1],\n",
       "          [1, 1]],\n",
       " \n",
       "         [[1, 1],\n",
       "          [0, 0],\n",
       "          [0, 1]]]),\n",
       " torch.Size([2, 3, 2]),\n",
       " tensor([[1, 0],\n",
       "         [0, 1],\n",
       "         [1, 1]]),\n",
       " torch.Size([3, 2]),\n",
       " tensor([[[4, 5],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[6, 7],\n",
       "          [0, 1]]]),\n",
       " tensor([[[4, 5],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[2, 6],\n",
       "          [0, 0]]]),\n",
       " tensor([[[4, 5],\n",
       "          [1, 0]],\n",
       " \n",
       "         [[1, 4],\n",
       "          [1, 1]]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([[[1,2,3],[1,0,0]],[[2,3,4],[0,1,0]]])\n",
    "b = torch.tensor([[[1,0],[0,1],[1,1]],[[1,1],[0,0],[0,1]]])\n",
    "\n",
    "a,a.shape, b, b.shape, b[0], b[0].shape,torch.matmul(a,b[0]), torch.matmul(a,b), torch.matmul(a[0],b), a[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn\n",
    "\n",
    "### embedding\n",
    "\n",
    "sometimes we have to create an embedding layer (*loop up layer*). The derivation from emebdding layer is straight forward: the last |n-1| dimension in embedding layer will be appended to the index tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 dimensional embedding:tensor([[[0.5483, 0.6040, 0.8072],\n         [0.2734, 0.9912, 0.5855]],\n\n        [[0.5239, 0.0344, 0.4192],\n         [0.0804, 0.4840, 0.0895]]]) of size torch.Size([2, 2, 3])\n\n2 dimensional embedding:tensor([[[[0.7808, 0.7868, 0.6942],\n          [0.5475, 0.7632, 0.5925],\n          [0.4733, 0.4298, 0.9889],\n          [0.2916, 0.9522, 0.1331],\n          [0.3567, 0.5843, 0.9117]],\n\n         [[0.9080, 0.9921, 0.0865],\n          [0.8223, 0.4205, 0.7956],\n          [0.0150, 0.7352, 0.6009],\n          [0.7414, 0.3398, 0.8795],\n          [0.7309, 0.1035, 0.8814]]],\n\n\n        [[[0.2508, 0.4999, 0.8504],\n          [0.1842, 0.2682, 0.2584],\n          [0.4942, 0.1009, 0.9256],\n          [0.5841, 0.6895, 0.1570],\n          [0.9514, 0.1604, 0.2270]],\n\n         [[0.8479, 0.4176, 0.6745],\n          [0.4648, 0.4139, 0.1350],\n          [0.7314, 0.8723, 0.5420],\n          [0.6580, 0.8016, 0.8920],\n          [0.6776, 0.1732, 0.4551]]]]) of size torch.Size([2, 2, 5, 3])\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = torch.rand((5,3))\n",
    "index_tensor = torch.tensor([[3,4],[0,1]]) # only tensor of dtype=torch.long works\n",
    "print(\"1 dimensional embedding:{} of size {}\\n\".format(embedding_layer[index_tensor], embedding_layer[index_tensor].shape))\n",
    "\n",
    "embedding_layer = torch.rand((5,5,3))\n",
    "print(\"2 dimensional embedding:{} of size {}\".format(embedding_layer[index_tensor], embedding_layer[index_tensor].shape))"
   ]
  },
  {
   "source": [
    "### Cosine Similarity\n",
    "`PyTorch` provides convenient api for computing cosine similarity between two tensor, however it's confusing when dimension is more than one.\n",
    "\n",
    "- From my perspective, the `dim` parameter can be viewed as the dimension to *compress*, which means computing cosine similarity along `dim` is actually transforming the vector on this dimension to a single value.\n",
    "- As for calculating, we first slice the tensor of given `dim` and compute cosine similarity pair-wise\n",
    "- when `dim` is higher dimension:\n",
    "    - `dim` = 0: value at the same place across the batch will be packed into a vector\n",
    "    - `dim` = -1: value at the last dimension will be collected into a vector"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "\n",
    "\" example for cosine similarity along the last dimension \"\n",
    "cos = CosineSimilarity(dim=2)\n",
    "\n",
    "a = torch.rand((3,2,3))\n",
    "b = torch.rand((3,2,3))\n",
    "\n",
    "c = a[0]\n",
    "d = b[0]\n",
    "\n",
    "e = a[:,0,:].unsqueeze(dim=1)\n",
    "f = b[:,0,:].unsqueeze(dim=2)\n",
    "g = a[:,1,:].unsqueeze(dim=1)\n",
    "h = b[:,1,:].unsqueeze(dim=2)\n",
    "\n",
    "result_1 = torch.matmul(e,f) / torch.sqrt(torch.matmul(e,e.permute(0,2,1)) * torch.matmul(f.permute(0,2,1),f))\n",
    "result_2 = torch.matmul(g,h) / torch.sqrt(torch.matmul(g,g.permute(0,2,1)) * torch.matmul(h.permute(0,2,1),h))\n",
    "\n",
    "cos_2 = CosineSimilarity(dim=1)\n",
    "cos(a,b), cos_2(c,d), result_1.squeeze(), result_2.squeeze()"
   ]
  },
  {
   "source": [
    "### Layer Normalization\n",
    "\n",
    "Layer Normalization is applied over the last given dimensions of the input tensor, i.e. `mean` and `variance` are calculated within the current input, rather than the whole batch"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[-0.5000,  0.5000,  0.0000],\n",
       "          [ 0.0000,  1.0000, -1.0000]],\n",
       " \n",
       "         [[ 1.0000,  2.0000,  3.0000],\n",
       "          [ 5.0000,  9.0000, 11.0000]]]),\n",
       " tensor([[[-0.7746,  0.7746,  0.0000],\n",
       "          [ 0.0000,  1.5492, -1.5492]],\n",
       " \n",
       "         [[-1.1352, -0.8627, -0.5903],\n",
       "          [-0.0454,  1.0444,  1.5893]]], grad_fn=<NativeLayerNormBackward>))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "LayerNorm = torch.nn.LayerNorm((2,3))\n",
    "a = torch.tensor([[[-0.5,0.5,0],[0,1,-1]],[[1,2,3],[5,9,11]]])\n",
    "a,LayerNorm(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.autograd\n",
    "Only when the operation in the forward phrase is **not differentiable** while you want the gradient to be pass through that you should rewrite torch.autograd, where you can define your own backward algorithm to give an approximate gradient of the **indifferentiable** operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}