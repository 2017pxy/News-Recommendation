{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bit4c03300bedca44f8b0013abe02048abc",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeating samples along axis\n",
    "\n",
    "*repeat_interleave* is equal to *cat and view*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[[1, 2]],\n\n        [[2, 3]]]) torch.Size([2, 1, 2])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1, 2]],\n",
       " \n",
       "         [[1, 2]],\n",
       " \n",
       "         [[2, 3]],\n",
       " \n",
       "         [[2, 3]]]),\n",
       " tensor([[[1, 2]],\n",
       " \n",
       "         [[1, 2]],\n",
       " \n",
       "         [[2, 3]],\n",
       " \n",
       "         [[2, 3]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "a =torch.tensor([[[1,2]],[[2,3]]])\n",
    "print(a,a.shape)\n",
    "\n",
    "a.repeat_interleave(repeats=2,dim=0),torch.cat([a.unsqueeze(dim=1)]*2,dim=1).view(-1,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### understanding *permute*\n",
    "\n",
    "let's suppose there is a tensor of $[dim0, dim1, dim2, dim3]$, then we permute it to $[dim3, dim1, dim2, dim0]$,\n",
    "    - **consequence**: origin value at $[a, b, c, d]$ will be switched to $[d, b, c, a]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros([5,4,3,2]),\n",
    "# say a=2, b=3, c=1, d=1,\n",
    "a[2,3,1,1] = 1,\n",
    "print(\"origin 1 at [2,3,1,1]: {}\".format(a[2,3,1,1])),\n",
    "b = a.permute(3,1,2,0),\n",
    "print(\"permuted 1 at [3,1,2,0]: {}\".format(b[1,3,1,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.autograd\n",
    "Only when the operation in the forward phrase is **not differentiable** while you want the gradient to be pass through that you should rewrite torch.autograd, where you can define your own backward algorithm to give an approximate gradient of the **indifferentiable** operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding\n",
    "\n",
    "sometimes we have to create an embedding layer (*loop up layer*). The derivation from emebdding layer is straight forward: the last |n-1| dimension in embedding layer will be appended to the index tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 dimensional embedding:tensor([[[0.9326, 0.0780, 0.4619],\n         [0.7300, 0.4935, 0.7460]],\n\n        [[0.2537, 0.5904, 0.6290],\n         [0.3936, 0.9263, 0.7734]]]) of size torch.Size([2, 2, 3])\n\n2 dimensional embedding:tensor([[[[0.3148, 0.9861, 0.3106],\n          [0.2436, 0.2787, 0.1736],\n          [0.2394, 0.4007, 0.8292],\n          [0.7823, 0.4570, 0.8251],\n          [0.0033, 0.7966, 0.3431],\n          [0.1534, 0.0922, 0.7102],\n          [0.5269, 0.0903, 0.5201],\n          [0.4941, 0.4445, 0.9990],\n          [0.9150, 0.0548, 0.5993],\n          [0.2121, 0.2611, 0.8124]],\n\n         [[0.9414, 0.2698, 0.3039],\n          [0.4300, 0.0050, 0.9384],\n          [0.3817, 0.5735, 0.0380],\n          [0.2574, 0.4992, 0.0408],\n          [0.7197, 0.6007, 0.9922],\n          [0.3779, 0.3335, 0.8303],\n          [0.7819, 0.6518, 0.3244],\n          [0.6018, 0.1290, 0.4581],\n          [0.0500, 0.8068, 0.1329],\n          [0.6273, 0.7432, 0.4093]]],\n\n\n        [[[0.3525, 0.9594, 0.4348],\n          [0.1865, 0.9445, 0.6464],\n          [0.9701, 0.9476, 0.2992],\n          [0.4149, 0.2359, 0.2136],\n          [0.1487, 0.7358, 0.0202],\n          [0.5987, 0.5195, 0.2892],\n          [0.6008, 0.2061, 0.7118],\n          [0.8720, 0.7932, 0.0296],\n          [0.9367, 0.8023, 0.4875],\n          [0.4861, 0.4282, 0.1082]],\n\n         [[0.6652, 0.7317, 0.8854],\n          [0.3639, 0.9898, 0.0235],\n          [0.9102, 0.5536, 0.2480],\n          [0.7893, 0.2123, 0.1879],\n          [0.7665, 0.4992, 0.4229],\n          [0.1744, 0.5717, 0.6371],\n          [0.2134, 0.5845, 0.3214],\n          [0.8182, 0.8395, 0.8035],\n          [0.9692, 0.3702, 0.8241],\n          [0.4176, 0.5776, 0.8483]]]]) of size torch.Size([2, 2, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = torch.rand((10,3))\n",
    "index_tensor = torch.tensor([[3,5],[0,9]]) # only tensor of dtype=torch.long works\n",
    "print(\"1 dimensional embedding:{} of size {}\\n\".format(embedding_layer[index_tensor], embedding_layer[index_tensor].shape))\n",
    "\n",
    "embedding_layer = torch.rand((10,10,3))\n",
    "print(\"2 dimensional embedding:{} of size {}\".format(embedding_layer[index_tensor], embedding_layer[index_tensor].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finding non-zero indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[1, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "a = torch.zeros(2,2)\n",
    "a[1,0] = 1\n",
    "a.nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}