{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bit4c03300bedca44f8b0013abe02048abc",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/peitian_zhang/Codes/NR')\n",
    "sys.path.append('/home/peitian_zhang/Codes/NR')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import gumbel_softmax,softmax\n",
    "from models.TestTensors import t_2_2_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0.8986, 0.8404],\n",
       "         [0.8575, 0.3225],\n",
       "         [0.8550, 0.8219]]),\n",
       " tensor([0.8986, 0.8404]),\n",
       " tensor([0.8986, 0.8575, 0.8550]),\n",
       " tensor([0.8404, 0.3225, 0.8219]))"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "from torch.nn import CosineSimilarity\n",
    "\n",
    "\" example for cosine similarity along the last dimension \"\n",
    "cos = CosineSimilarity(dim=-1)\n",
    "\n",
    "a = torch.rand((3,2,3))\n",
    "b = torch.rand((3,2,3))\n",
    "\n",
    "c = a[0]\n",
    "d = b[0]\n",
    "\n",
    "e = a[:,0,:].unsqueeze(dim=1)\n",
    "f = b[:,0,:].unsqueeze(dim=2)\n",
    "g = a[:,1,:].unsqueeze(dim=1)\n",
    "h = b[:,1,:].unsqueeze(dim=2)\n",
    "\n",
    "result_1 = torch.matmul(e,f) / torch.sqrt(torch.matmul(e,e.permute(0,2,1)) * torch.matmul(f.permute(0,2,1),f))\n",
    "result_2 = torch.matmul(g,h) / torch.sqrt(torch.matmul(g,g.permute(0,2,1)) * torch.matmul(h.permute(0,2,1),h))\n",
    "\n",
    "cos_2 = CosineSimilarity(dim=1)\n",
    "cos(a,b), cos_2(c,d), result_1.squeeze(), result_2.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[[0.3279, 0.7263, 0.7824],\n",
       "           [0.5332, 0.0821, 0.0460]],\n",
       " \n",
       "          [[0.0161, 0.1543, 0.4402],\n",
       "           [0.9077, 0.7735, 0.8705]],\n",
       " \n",
       "          [[0.0439, 0.1470, 0.4554],\n",
       "           [0.1357, 0.9111, 0.3551]]],\n",
       " \n",
       " \n",
       "         [[[0.4728, 0.3827, 0.7409],\n",
       "           [0.5877, 0.7028, 0.0544]],\n",
       " \n",
       "          [[0.0658, 0.2674, 0.4417],\n",
       "           [0.5513, 0.3435, 0.1445]],\n",
       " \n",
       "          [[0.2769, 0.9772, 0.3803],\n",
       "           [0.9192, 0.6064, 0.4294]]],\n",
       " \n",
       " \n",
       "         [[[0.9220, 0.2475, 0.1829],\n",
       "           [0.7452, 0.8068, 0.5152]],\n",
       " \n",
       "          [[0.8324, 0.4537, 0.0284],\n",
       "           [0.5481, 0.4037, 0.9052]],\n",
       " \n",
       "          [[0.4446, 0.2342, 0.1037],\n",
       "           [0.4158, 0.3318, 0.9600]]],\n",
       " \n",
       " \n",
       "         [[[0.9149, 0.7405, 0.5799],\n",
       "           [0.0782, 0.2966, 0.6611]],\n",
       " \n",
       "          [[0.6452, 0.9098, 0.6883],\n",
       "           [0.8589, 0.1267, 0.3188]],\n",
       " \n",
       "          [[0.3832, 0.5644, 0.1832],\n",
       "           [0.8251, 0.3839, 0.3712]]]]),\n",
       " tensor([0.3279, 0.0161, 0.0439]))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "cos = CosineSimilarity(dim=2)\n",
    "a = torch.rand((4,3,2,3))\n",
    "b = torch.rand((4,3,2,3))\n",
    "a, a[0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 1., 0., 0.]]),\n",
       " tensor([[0., 0., 1., 0., 0., 0.]]),\n",
       " tensor([[nan, nan, nan, nan, nan, nan]]))"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "e = gumbel_softmax(c,tau=0.1,hard=True)\n",
    "f = gumbel_softmax(a,tau=0.1,hard=True)\n",
    "g = gumbel_softmax(m,tau=0.1,hard=True)\n",
    "e,f,g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/peitian_zhang/Codes/NR')\n",
    "sys.path.append('/home/peitian_zhang/Codes/NR')\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from datetime import datetime\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.MIND import MIND_iter,MIND_map\n",
    "from utils.utils import getLoss,constructBasicDict,run_eval,run_train\n",
    "from models.NPA import NPAModel\n",
    "\n",
    "if __name__ == \"__main__\":    hparams = {\n",
    "    'mode':\"large\",\n",
    "    'batch_size':100,\n",
    "    'title_size':30,\n",
    "    'his_size':50,   \n",
    "    'npratio':4,\n",
    "    'dropout_p':0.2,\n",
    "    'filter_num':400,\n",
    "    'embedding_dim':300,\n",
    "    'user_dim':50,\n",
    "    'preference_dim':200,\n",
    "    'metrics':'group_auc,ndcg@4,mean_mrr',\n",
    "    'gpu':'cuda:0',\n",
    "    'attrs': ['title'],\n",
    "}\n",
    "\n",
    "news_file_train = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_train/news.tsv'\n",
    "news_file_test = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_dev/news.tsv'\n",
    "news_file_pair = (news_file_train,news_file_test)\n",
    "\n",
    "behavior_file_train = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_train/behaviors.tsv'\n",
    "behavior_file_test = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_dev/behaviors.tsv'\n",
    "behavior_file_pair = (behavior_file_train,behavior_file_test)\n",
    "\n",
    "save_path = '/home/peitian_zhang/Codes/NR/models/model_param/NPA_'+ hparams['mode'] +'.model'\n",
    "\n",
    "if not os.path.exists('data/dictionaries/vocab_{}_{}.pkl'.format(hparams['mode'],'_'.join(hparams['attrs']))):\n",
    "    constructBasicDict(news_file_pair,behavior_file_pair,hparams['mode'],hparams['attrs'])\n",
    "\n",
    "device = torch.device(hparams['gpu']) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "dataset_train = MIND_map(hparams=hparams,news_file=news_file_train,behaviors_file=behavior_file_train)\n",
    "dataset_test = MIND_iter(hparams=hparams,news_file=news_file_test,behaviors_file=behavior_file_test)\n",
    "\n",
    "vocab = dataset_train.vocab\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab.load_vectors(embedding)\n",
    "\n",
    "loader_train = DataLoader(dataset_train,batch_size=hparams['batch_size'],shuffle=True,pin_memory=True,num_workers=20,drop_last=True)\n",
    "loader_test = DataLoader(dataset_test,batch_size=hparams['batch_size'],pin_memory=True,num_workers=0,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[[0.2782, 0.6213, 0.3146]]],\n",
       " \n",
       " \n",
       "         [[[0.5008, 0.1810, 0.9057]]]]),\n",
       " tensor([[[[0.6608],\n",
       "           [0.3568],\n",
       "           [0.1521]],\n",
       " \n",
       "          [[0.1186],\n",
       "           [0.2018],\n",
       "           [0.5153]],\n",
       " \n",
       "          [[0.8943],\n",
       "           [0.6125],\n",
       "           [0.4719]]],\n",
       " \n",
       " \n",
       "         [[[0.8186],\n",
       "           [0.5829],\n",
       "           [0.4187]],\n",
       " \n",
       "          [[0.7143],\n",
       "           [0.3065],\n",
       "           [0.9706]],\n",
       " \n",
       "          [[0.5004],\n",
       "           [0.4140],\n",
       "           [0.0489]]]]),\n",
       " tensor([[[[0.4534]],\n",
       " \n",
       "          [[0.3205]],\n",
       " \n",
       "          [[0.7778]]],\n",
       " \n",
       " \n",
       "         [[[0.8947]],\n",
       " \n",
       "          [[1.2923]],\n",
       " \n",
       "          [[0.3698]]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "a = torch.rand((2,1,1,3))\n",
    "b = torch.rand((2,3,3,1))\n",
    "\n",
    "a, b, torch.matmul(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}