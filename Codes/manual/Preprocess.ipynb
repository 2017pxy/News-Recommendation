{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bit4c03300bedca44f8b0013abe02048abc",
   "display_name": "Python 3.7.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.chdir('/home/peitian_zhang/Codes/NR')\n",
    "sys.path.append('/home/peitian_zhang/Codes/NR')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import GloVe\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.MIND import MIND_iter,MIND_map\n",
    "from utils.utils import constructBasicDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'npratio':4,\n",
    "    'mode':'demo',\n",
    "    'batch_size':5,\n",
    "    'his_size':2,\n",
    "    'title_size':5,\n",
    "    'gpu':'cuda:0',\n",
    "    'attrs': ['title','category','subcategory']\n",
    "}\n",
    "\n",
    "# customize your path here\n",
    "news_file_train = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_train/news.tsv'\n",
    "news_file_test = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_dev/news.tsv'\n",
    "news_file_pair = (news_file_train,news_file_test)\n",
    "\n",
    "behavior_file_train = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_train/behaviors.tsv'\n",
    "behavior_file_test = '/home/peitian_zhang/Data/MIND/MIND'+hparams['mode']+'_dev/behaviors.tsv'\n",
    "behavior_file_pair = (behavior_file_train,behavior_file_test)\n",
    "\n",
    "save_path = '/home/peitian_zhang/Codes/NR/models/model_param/NPA_'+ hparams['mode'] +'.model'\n",
    "\n",
    "if not os.path.exists('data/dictionaries/vocab_{}_{}.pkl'.format(hparams['mode'],'_'.join(hparams['attrs']))):\n",
    "    constructBasicDict(news_file_pair,behavior_file_pair,hparams['mode'],hparams['attrs'])\n",
    "\n",
    "device = torch.device(hparams['gpu']) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "dataset_train = MIND_map(hparams=hparams,news_file=news_file_train,behaviors_file=behavior_file_train)\n",
    "\n",
    "dataset_test = MIND_iter(hparams=hparams,news_file=news_file_test,behaviors_file=behavior_file_test)\n",
    "\n",
    "vocab = dataset_train.vocab\n",
    "embedding = GloVe(dim=300,cache='.vector_cache')\n",
    "vocab.load_vectors(embedding)\n",
    "\n",
    "# vocab_test = dataset_test.vocab\n",
    "# vocab_test.load_vectors(embedding)\n",
    "\n",
    "loader_train = DataLoader(dataset_train,batch_size=hparams['batch_size'],shuffle=True,pin_memory=True,num_workers=3,drop_last=True)\n",
    "loader_test = DataLoader(dataset_test,batch_size=hparams['batch_size'],pin_memory=True,num_workers=0,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'user_index': tensor([[ 233],\n",
       "          [ 821],\n",
       "          [1461],\n",
       "          [1481],\n",
       "          [  30]]),\n",
       "  'clicked_title': tensor([[[ 2632,  2172,  1261,    11, 14704],\n",
       "           [  450,    21, 31928,   116,  1925]],\n",
       "  \n",
       "          [[ 2366,  1217,  5202,    35,  5965],\n",
       "           [  450,  1923,    40,  1387,    11]],\n",
       "  \n",
       "          [[  367, 11233,   365,   205,     5],\n",
       "           [  747,   799,   665,   847,  4014]],\n",
       "  \n",
       "          [[    8,   429,    10,  6047,   471],\n",
       "           [ 3965,   229,   752,    40,     9]],\n",
       "  \n",
       "          [[   15,   157,    91,  3080,     7],\n",
       "           [   98,   528,   565,  1102,  2501]]]),\n",
       "  'clicked_category': tensor([[[ 3],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[ 3],\n",
       "           [ 4]],\n",
       "  \n",
       "          [[ 3],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[34],\n",
       "           [28]],\n",
       "  \n",
       "          [[ 3],\n",
       "           [28]]]),\n",
       "  'clicked_subcategory': tensor([[[ 13],\n",
       "           [ 43]],\n",
       "  \n",
       "          [[ 43],\n",
       "           [ 45]],\n",
       "  \n",
       "          [[ 23],\n",
       "           [ 23]],\n",
       "  \n",
       "          [[189],\n",
       "           [ 86]],\n",
       "  \n",
       "          [[ 43],\n",
       "           [ 86]]]),\n",
       "  'candidate_title': tensor([[[   53,    92,   518,  2426,   446],\n",
       "           [    8,    74,  9127,  1244,    26],\n",
       "           [10669,     6,  9955,    17,     8],\n",
       "           [  649,   485,    49,   454,   811],\n",
       "           [ 7486, 24719,    21,    15,  2711]],\n",
       "  \n",
       "          [[  328,   821,   457,  7150,    16],\n",
       "           [   90,     9,     8,    74,   906],\n",
       "           [  177,     9,  5138,   453,  1524],\n",
       "           [ 4377,   123,   297,  4022,    21],\n",
       "           [  537,   509,  2515,  2839,  1400]],\n",
       "  \n",
       "          [[  418,  1312,    76,    12,   235],\n",
       "           [ 6829,  3078,    46,  7801,    11],\n",
       "           [  242,   345,    15,    98,     9],\n",
       "           [  103,    66,  6168,   568,     6],\n",
       "           [ 2007,  7951,   319,    10,  1698]],\n",
       "  \n",
       "          [[ 2517,    87,    56,   363, 10432],\n",
       "           [  126,   480,     7,  3871,  2069],\n",
       "           [   92,    91,  1483,   299,   190],\n",
       "           [ 9886,  2011,  2012,  2537,  8929],\n",
       "           [    0, 27212,  1855,  9353,     5]],\n",
       "  \n",
       "          [[   40,     9,     8,   496,  1739],\n",
       "           [ 8483,  6593,  7779,  1030,    17],\n",
       "           [ 1648,  2649,  1212,    19, 19830],\n",
       "           [  470,  2624,   788,  7664,     0],\n",
       "           [    8,  1475,   299,    39,  2195]]]),\n",
       "  'candidate_category': tensor([[[ 34],\n",
       "           [138],\n",
       "           [  3],\n",
       "           [  4],\n",
       "           [ 42]],\n",
       "  \n",
       "          [[  4],\n",
       "           [ 27],\n",
       "           [138],\n",
       "           [  4],\n",
       "           [  3]],\n",
       "  \n",
       "          [[  4],\n",
       "           [ 22],\n",
       "           [ 28],\n",
       "           [ 28],\n",
       "           [ 28]],\n",
       "  \n",
       "          [[  3],\n",
       "           [  3],\n",
       "           [ 34],\n",
       "           [ 42],\n",
       "           [  3]],\n",
       "  \n",
       "          [[  3],\n",
       "           [ 29],\n",
       "           [  3],\n",
       "           [138],\n",
       "           [ 24]]]),\n",
       "  'candidate_subcategory': tensor([[[30374],\n",
       "           [  485],\n",
       "           [   13],\n",
       "           [   38],\n",
       "           [  417]],\n",
       "  \n",
       "          [[   38],\n",
       "           [  413],\n",
       "           [  470],\n",
       "           [   41],\n",
       "           [  905]],\n",
       "  \n",
       "          [[   41],\n",
       "           [  219],\n",
       "           [   86],\n",
       "           [ 1119],\n",
       "           [ 1098]],\n",
       "  \n",
       "          [[  631],\n",
       "           [   13],\n",
       "           [  692],\n",
       "           [  838],\n",
       "           [  905]],\n",
       "  \n",
       "          [[  631],\n",
       "           [  141],\n",
       "           [   13],\n",
       "           [  781],\n",
       "           [   28]]]),\n",
       "  'labels': tensor([[1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0],\n",
       "          [1, 0, 0, 0, 0]])},\n",
       " {'impression_index': tensor([0, 0, 0, 0, 0]),\n",
       "  'user_index': tensor([[1929],\n",
       "          [1929],\n",
       "          [1929],\n",
       "          [1929],\n",
       "          [1929]]),\n",
       "  'clicked_title': tensor([[[3805,   10, 3940, 4523, 2712],\n",
       "           [ 728,  663,  597,   31,  921]],\n",
       "  \n",
       "          [[3805,   10, 3940, 4523, 2712],\n",
       "           [ 728,  663,  597,   31,  921]],\n",
       "  \n",
       "          [[3805,   10, 3940, 4523, 2712],\n",
       "           [ 728,  663,  597,   31,  921]],\n",
       "  \n",
       "          [[3805,   10, 3940, 4523, 2712],\n",
       "           [ 728,  663,  597,   31,  921]],\n",
       "  \n",
       "          [[3805,   10, 3940, 4523, 2712],\n",
       "           [ 728,  663,  597,   31,  921]]]),\n",
       "  'clicked_category': tensor([[[72],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[72],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[72],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[72],\n",
       "           [ 3]],\n",
       "  \n",
       "          [[72],\n",
       "           [ 3]]]),\n",
       "  'clicked_subcategory': tensor([[[204],\n",
       "           [ 13]],\n",
       "  \n",
       "          [[204],\n",
       "           [ 13]],\n",
       "  \n",
       "          [[204],\n",
       "           [ 13]],\n",
       "  \n",
       "          [[204],\n",
       "           [ 13]],\n",
       "  \n",
       "          [[204],\n",
       "           [ 13]]]),\n",
       "  'candidate_title': tensor([[[  244,  9107,     5,  1664,  1749]],\n",
       "  \n",
       "          [[   92,   625,   366,  6498,    69]],\n",
       "  \n",
       "          [[  981,  1192,  1222,    21,    69]],\n",
       "  \n",
       "          [[    8, 15836,   429,  2754,    51]],\n",
       "  \n",
       "          [[  851,    17,   120,    50,   143]]]),\n",
       "  'candidate_category': tensor([[[  4]],\n",
       "  \n",
       "          [[ 28]],\n",
       "  \n",
       "          [[  4]],\n",
       "  \n",
       "          [[ 72]],\n",
       "  \n",
       "          [[138]]]),\n",
       "  'candidate_subcategory': tensor([[[ 14]],\n",
       "  \n",
       "          [[692]],\n",
       "  \n",
       "          [[ 14]],\n",
       "  \n",
       "          [[259]],\n",
       "  \n",
       "          [[470]]]),\n",
       "  'labels': tensor([[0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [0],\n",
       "          [0]])})"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "a = next(iter(loader_train))\n",
    "b = next(iter(loader_test))\n",
    "a,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tailor Data to demo size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailorData('D:/Data/NR_data/MINDsmall_dev/behaviors.tsv',300)\n",
    "tailorData('D:/Data/NR_data/MINDsmall_train/behaviors.tsv',300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze MIND Datasets\n",
    "- average title length\n",
    "- average abstract length\n",
    "- average history length\n",
    "- average impression capacity\n",
    "- count of history exceeding 50\n",
    "- count of multi-clicked impressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_title_length = 0\n",
    "avg_abstract_length = 0\n",
    "avg_his_length = 0\n",
    "avg_imp_length = 0\n",
    "cnt_his_lg_50 = 0\n",
    "cnt_imp_multi = 0\n",
    "\n",
    "with open(news_file_train,\"r\",encoding='utf-8') as rd:\n",
    "    count = 0\n",
    "    for idx in rd:\n",
    "        nid, vert, subvert, title, ab, url, _, _ = idx.strip(\"\\n\").split('\\t')\n",
    "        avg_title_length += len(title.split(' '))\n",
    "        avg_abstract_length += len(ab.split(' '))\n",
    "        count += 1\n",
    "avg_title_length = avg_title_length/count\n",
    "avg_abstract_length = avg_abstract_length/count\n",
    "\n",
    "with open(behavior_file_train, \"r\", encoding='utf-8') as rd:\n",
    "    count = 0\n",
    "    for idx in rd:\n",
    "        uid, time, history, impr = idx.strip(\"\\n\").split('\\t')[-4:]\n",
    "        his = history.split(' ')\n",
    "        imp = impr.split(' ')\n",
    "        if len(his) > 50:\n",
    "            cnt_his_lg_50 += 1\n",
    "        if len(imp) > 50:\n",
    "            cnt_imp_multi += 1\n",
    "        avg_his_length += len(his)\n",
    "        avg_imp_length += len(imp)\n",
    "        count += 1\n",
    "avg_his_length = avg_his_length/count\n",
    "avg_imp_length = avg_imp_length/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "avg_title_length:10.67731736385395\n avg_abstract_length:36.4448570331045\n avg_his_length:32.99787212887438\n avg_impr_length:37.40116394684935\n cnt_his_lg_50:447829\n cnt_imp_multi:567571\n"
     ]
    }
   ],
   "source": [
    "print(\"avg_title_length:{}\\n avg_abstract_length:{}\\n avg_his_length:{}\\n avg_impr_length:{}\\n cnt_his_lg_50:{}\\n cnt_imp_multi:{}\".format(avg_title_length,avg_abstract_length,avg_his_length,avg_imp_length,cnt_his_lg_50,cnt_imp_multi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}